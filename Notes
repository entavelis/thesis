27-00-36 Sigmoid
28-09-23 Leaky ReLu
28-11-35 Rate 0.8 - betas + weight decay - mask 200
      0.781% 	  9.375% 	  38.281%
      0.781% 	  7.031% 	  42.969%
28-13-14 Rate 0.8 - betas + weight decay - no mask
      0.781% 	  6.250% 	  39.844%
28-15-39 Rate 0.8 - betas + weight decay - mask 100
28-16-45 Sum - Max(cm_loss,-0.001) - betas + weight decay - mask 200
29-00-28 Sum - Max(similarity * cm_loss,-0.01) - mask 200
shitty
29-00-30 Sum - Max(similarity * cm_loss,-0.1) - mask 200
shitty
promising

29-12-10 k=3 - similarity(- 0.5)/k - mask 100 - txtLR0.0005
29-12-14 k=5- similarity(- 1)/2*k - mask 100 - txtLR0.0005
29-14-24 k=5- reverse similarity/k - mask 100 - txtLR0.0005 txtLoss- CosineCMloss

29-15-4
29-01-08 Sum - similarity(- 0.5 iff 0) * cm_loss - mask 2003 k=10- similarity(- 1)/2*k - mask 100 - txtLR0.0005 txtLoss- CosineCMloss


Check Different Masks
Check different loss configurations
Check Different LR

- Removed Sigmoid activation at the end of the Decoder

Check initial values of image vectors

06-29 12:03 learning rate = 0.0001 and betas enables
06-29 12:07 learning rate = 0.0001 and betas enables, mask = 200
06-29 14:22 learning rate = 0.0001 and betas enables, mask = 100, rates inverted, weight decay
06-29 16:53 as above but changed emb to be memory bank
07-01 12:52 not mem bank rate = 0.8, MSE
07-01 16;55 not mem bank rate = 0.8
07-01 18.16 with sigmoid

07-02 15.38 64x64, rate = 0.8, lr = 0.001
07-02 15.38 64x64, rate = 0.8, lr = 0.0001
07-02 15.38 64x64, rate = 0.8, lr = 0.0001

16.32 only images
